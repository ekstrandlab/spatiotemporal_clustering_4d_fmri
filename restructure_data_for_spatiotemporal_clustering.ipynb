{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3532c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Author: Chelsea Ekstrand <chelsea.ekstrand@uleth.ca>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fedde36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import functions\n",
    "\n",
    "import numpy as np\n",
    "import re\n",
    "import nibabel as nib\n",
    "from glob import glob\n",
    "from os import path\n",
    "\n",
    "def natural_sort(l): \n",
    "    convert = lambda text: int(text) if text.isdigit() else text.lower() \n",
    "    alphanum_key = lambda key: [convert(c) for c in re.split('([0-9]+)', key)] \n",
    "    return sorted(l, key=alphanum_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b812cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters\n",
    "\n",
    "fmri_path = '/media/ekstrand/BackupPlus2/NaturalisticDataset_v2/'# path to subject directories in BIDS format\n",
    "cond1_path = path.join(fmri_path, 'face_timings_for_FIR') # path to onset and duration text files for condition one\n",
    "cond2_path = path.join(fmri_path, 'noface_timings_for_FIR')# path to onset and duration text files for condition one\n",
    "cond1name = 'face'\n",
    "cond2name = 'noface'\n",
    "task = '500daysofsummer'# BIDS task name\n",
    "suffix = 'bold_no_blur_no_censor_ica'# end of proprocessed filename after task\n",
    "saveDir_cond1 = path.join(fmri_path,'sub_face_averages') # path to save averaged fMRI files for condition 1\n",
    "saveDir_cond2 = path.join(fmri_path,'sub_noface_averages') # path to save averaged fMRI files for condition 1\n",
    "time = 11 # number of timepoints to model\n",
    "lag = 3 # how many seconds after the event to model to account for the slow BOLD function\n",
    "TR = 1 # fMRI repetition time\n",
    "saveSubs = 'n' # save individual subject averages? 'y'es or 'n'o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772b5270",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_condition_timing_data(fmri_data,beh_data,fill,tr,volumes):\n",
    "    ind = 0\n",
    "    for c in beh_data:\n",
    "        # calculate the onset volume by dividing the onset time by the TR, rounding down to nearest int\n",
    "        vol = int((c[0]/tr) + lag) \n",
    "        print(vol)\n",
    "        fill[:,:,:,:,ind] = fmri_data[:,:,:,vol:vol+volumes]\n",
    "        ind = ind + 1\n",
    "\n",
    "    #calculate average of all the condition 1 instances\n",
    "    ave = np.mean(fill,axis=4)\n",
    "\n",
    "    # reshape data to time, x,y,z format needed for clustering\n",
    "    ave = np.transpose(ave,(3,0,1,2))\n",
    "    return(ave)\n",
    "\n",
    "def restructure_data(subs,c1_path,c2_path,sSubs):\n",
    "    count = 0\n",
    "    for s in subs:\n",
    "        sub_num = s.split('/')[-1].split('_')[0]\n",
    "        print(sub_num)\n",
    "        cond1file = glob(path.join(c1_path,sub_num + '_*.txt'))\n",
    "        cond2file = glob(path.join(c2_path,sub_num + '_*.txt'))\n",
    "\n",
    "        # load functional data\n",
    "        load_data = nib.load(s)\n",
    "        data = load_data.get_fdata()\n",
    "        x,y,z,t = np.shape(data)\n",
    "        print(x,y,z,t)\n",
    "\n",
    "        # load event data\n",
    "        cond1_data = np.loadtxt(cond1file[0],delimiter=' ')\n",
    "        cond2_data = np.loadtxt(cond2file[0],delimiter=' ')\n",
    "\n",
    "        cond_fill = np.zeros((x,y,z,time,len(cond1_data)))\n",
    "\n",
    "        cond1_ave = get_condition_timing_data(data,cond1_data,cond_fill,TR,volumes)\n",
    "        cond2_ave = get_condition_timing_data(data,cond2_data,cond_fill,TR,volumes)\n",
    "\n",
    "        master_fill_cond1[count,:,:,:,:] = cond1_ave\n",
    "        master_fill_cond2[count,:,:,:,:] = cond2_ave\n",
    "\n",
    "        if sSubs == 'y':\n",
    "            # save condition 1 average file for each subject\n",
    "            saveFileCond1 = path.join(saveDir_cond1,sub_num + '_task-' + task + '_cond-' + cond1name + '_TRtimepoints-' + str(t) + '_average.nii.gz')\n",
    "            saveCond1 = nib.Nifti1Image(cond1_ave,load_data.affine)\n",
    "            nib.save(saveCond1,saveFileCond1)\n",
    "\n",
    "            # save condition 1 average file for each subject\n",
    "            saveFileCond2 = path.join(saveDir_cond2,sub_num + '_task-' + task + '_cond-' + cond2name + '_TRtimepoints-' + str(t) + '_average.nii.gz')\n",
    "            saveCond2 = nib.Nifti1Image(cond2_ave,load_data.affine)\n",
    "            nib.save(saveCond2,saveFileCond2)   \n",
    "\n",
    "        count = count+1\n",
    "    return(master_fill_cond1,master_fill_cond2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b16d0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# restructure functional data for spatiotemporal clustering\n",
    "\n",
    "\n",
    "\n",
    "subjects = glob(path.join(fmri_path,'sub-*/func/sub-*_task-' + task + '_' + suffix + '.nii.gz'))\n",
    "subjects = natural_sort(subjects)\n",
    "\n",
    "dim_data = nib.load(subjects[0])\n",
    "get_dim_data = dim_data.get_fdata()\n",
    "dim_x,dim_y,dim_z,dim_t = np.shape(get_dim_data)\n",
    "volumes = int(time/TR)\n",
    "\n",
    "#create new matrices to fill for saving\n",
    "master_fill_cond1 = np.empty((len(subjects),volumes,dim_x,dim_y,dim_z))\n",
    "master_fill_cond2 = np.empty((len(subjects),volumes,dim_x,dim_y,dim_z))\n",
    "\n",
    "print(np.shape(master_fill_cond1),np.shape(master_fill_cond2))\n",
    "\n",
    "if time % TR != 0:\n",
    "    print('ERROR: Desired timepoints not divisible by TR!')\n",
    "elif path.exists(path.join(saveDir_cond2,str(len(subjects)) + 'sub_average_task-' + task + '_cond-' + cond2name + '_TRtimepoints-' + str(volumes) + '_lag-' + str(lag) + '.nii.gz')) == False:\n",
    "    big_fill_cond1, big_fill_cond2 = restructure_data(subjects,cond1_path,cond2_path,saveSubs)\n",
    "    \n",
    "    saveCond1masterFile = path.join(saveDir_cond1,str(len(subjects)) + 'sub_average_task-' + task + '_cond-' + cond1name + '_TRtimepoints-' + str(volumes) + '_lag-' + str(lag) + '.nii.gz')\n",
    "    saveCond2masterFile = path.join(saveDir_cond2,str(len(subjects)) + 'sub_average_task-' + task + '_cond-' + cond2name + '_TRtimepoints-' + str(volumes) + '_lag-' + str(lag) + '.nii.gz')\n",
    "    \n",
    "    saveCond1master = nib.Nifti1Image(big_fill_cond1,dim_data.affine)\n",
    "    nib.save(saveCond1master,saveCond1masterFile)\n",
    "    saveCond2master = nib.Nifti1Image(big_fill_cond2,dim_data.affine)\n",
    "    nib.save(saveCond2master,saveCond2masterFile)\n",
    "else:\n",
    "    print('File already exists!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a054f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
